{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPIpod2c25swcktp/1YiaqW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nagendra-Bankupalli/day4_example/blob/main/tensor_data_types.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "WaQ8cpWkyeGD"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# data types of tensors\n",
        "\n",
        "'''\n",
        "floating - for  most deep learning tasks -> float32, float64 , forat16\n",
        "integers - for categorical data and indicies -> int32, int64, int8\n",
        "boolean - mask or logical operations / true/false\n",
        "complex number - advanced computation -> complex64, complex128\n",
        "\n",
        "memory consumption : float16 << float32 << float64\n",
        "computation : lower prcision will be faster on GPU\n",
        "numerical precision : flaot64 is more precise than float32\n",
        "\n",
        "'''\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "wlDpIHWZyolJ",
        "outputId": "96b89804-e9d7-4743-cffc-e73717a4ed7e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nfloating - for  most deep learning tasks -> float32, float64 , forat16 \\nintegers - for categorical data and indicies -> int32, int64, int8 \\nboolean - mask or logical operations / true/false \\ncomplex number - advanced computation -> complex64, complex128 \\n\\nmemory consumption : float16 << float32 << float64\\ncomputation : lower prcision will be faster on GPU\\nnumerical precision : flaot64 is more precise than float32\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "default_tensor = torch.tensor([1.5,2.5,3.5])\n",
        "print(default_tensor.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fMakRKPmymbL",
        "outputId": "e98c6b85-03dd-4c95-c367-d1d9fec8c9e9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.float32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "float_tensor = torch.tensor([1.5,2.5,3.5], dtype=torch.float64)\n",
        "print(float_tensor.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mlY-w-qy0HFA",
        "outputId": "9071f112-ff3e-46b5-9472-b6a0178e901e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "int32_tensor = torch.tensor([1.5,2.5,3.5], dtype=torch.int32)\n",
        "print(int32_tensor.dtype)\n",
        "print(int32_tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I37we01U0UbZ",
        "outputId": "1dc87a39-7e8d-4a6b-ccf4-9df964471b44"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.int32\n",
            "tensor([1, 2, 3], dtype=torch.int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bool_tensor = torch.tensor([True, False, True], dtype=torch.bool)\n",
        "print(bool_tensor.dtype)\n",
        "print(bool_tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GY9KyTtu0e_t",
        "outputId": "b4467026-b673-4c36-e1ad-ac3a00a00abd"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.bool\n",
            "tensor([ True, False,  True])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# convert to int tensor from float\n",
        "\n",
        "float_tensor  = torch.tensor([1.5,2.5,3.5])\n",
        "print(float_tensor.dtype)\n",
        "print(float_tensor)\n",
        "print(\" \")\n",
        "int_tensor = float_tensor.to(torch.int64)\n",
        "print(int_tensor)\n",
        "print(int_tensor.dtype)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FJzz6G1O05Dt",
        "outputId": "2a53cb0d-d53e-433d-c89c-2a9a90a88ca7"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.float32\n",
            "tensor([1.5000, 2.5000, 3.5000])\n",
            " \n",
            "tensor([1, 2, 3])\n",
            "torch.int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## impact of datatype on memory\n",
        "\n",
        "float32_tensor = torch.ones(1000, dtype=torch.float32)\n",
        "float64_tensor = torch.ones(1000, dtype=torch.float64)\n",
        "\n",
        "# tensor.element_size() => size of one element size in bytes\n",
        "# element_size()\n",
        "# nelement - number of elemetns\n",
        "\n",
        "print(float32_tensor.element_size())\n",
        "print(float32_tensor.nelement())\n",
        "print(\"memory used by float32 tensor \", float32_tensor.element_size() * float32_tensor.nelement())\n",
        "print(\" \")\n",
        "print(float64_tensor.element_size())\n",
        "print(float64_tensor.nelement())\n",
        "print(\"memory used by float64 tensor \", float64_tensor.element_size() * float64_tensor.nelement())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Op_tOMV1rru",
        "outputId": "9800de49-97bd-4c7f-94f4-2db74ea7d2ad"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4\n",
            "1000\n",
            "memory used by float32 tensor  4000\n",
            " \n",
            "8\n",
            "1000\n",
            "memory used by float64 tensor  8000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# float32 --> default for most NN models\n",
        "# float64 --> high precision computation\n",
        "# int32 --> general purpose integer\n",
        "# int64 --> tensor undices\n",
        "# int8 & int16 --> reduce memory usage\n",
        "# bool --> mask and logical operations\n",
        "# float16 --> half precision of default folat type , redude memory usage\n",
        "# complex64 --> advanced computation\n"
      ],
      "metadata": {
        "id": "HbzDPWRP3VMr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "w_WchL-03FQ-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}